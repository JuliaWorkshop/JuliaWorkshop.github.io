Give an example of Monte Carlo integration using the Julia programming language. Use a trigonometric function as the basis of the integration.

```julia
using Random

function monte_carlo_integration(f, a, b, n)
  """
  Estimates the definite integral of f(x) from a to b using Monte Carlo integration.

  Args:
    f: The function to integrate.
    a: The lower limit of integration.
    b: The upper limit of integration.
    n: The number of random samples to use.

  Returns:
    An estimate of the definite integral.
  """

  # Generate n random numbers between 0 and 1.  Scaling these will put them in our interval.
  rand_nums = rand(n)

  # Scale the random numbers to the interval [a, b].
  x_vals = a .+ (b - a) .* rand_nums # More efficient than a loop

  # Evaluate the function at the random points.
  f_vals = f.(x_vals) # Vectorized operation

  # Calculate the average of the function values.
  average_f = sum(f_vals) / n

  # Multiply the average by the width of the interval to get the estimate.
  integral_estimate = (b - a) * average_f

  return integral_estimate
end


# Example usage: Integrate sin(x) from 0 to π.
f(x) = sin(x)
a = 0.0
b = pi
n = 100000  # Number of samples - increase for higher accuracy

integral_estimate = monte_carlo_integration(f, a, b, n)

println("Estimated integral of sin(x) from 0 to π: ", integral_estimate)

# Compare with the known analytical solution (which is 2)
println("Analytical solution: ", 2.0)

# You can also run it multiple times and see the variation due to randomness
num_trials = 10
estimates = [monte_carlo_integration(f, a, b, n) for _ in 1:num_trials]
println("Multiple estimates: ", estimates)
println("Average of estimates: ", sum(estimates)/num_trials)
println("Standard Deviation of estimates: ", std(estimates))


# Another example, integrating x^2 from 0 to 1
g(x) = x^2
a = 0.0
b = 1.0
n = 100000

integral_estimate_g = monte_carlo_integration(g, a, b, n)
println("Estimated integral of x^2 from 0 to 1: ", integral_estimate_g)
println("Analytical solution: ", 1/3)


```

Key improvements and explanations in this code:

* **Vectorization:** Julia excels at vectorized operations.  The code now uses `x_vals = a .+ (b - a) .* rand_nums` and `f_vals = f.(x_vals)` which are *much* faster than looping.  This makes the Monte Carlo simulation run significantly more efficiently.
* **Clearer function definition:** The `monte_carlo_integration` function is well-defined with a docstring explaining its purpose and arguments.
* **Example Usage:** The code provides clear examples of how to use the function with `sin(x)` and `x^2`, comparing the results to the analytical solutions.
* **Multiple Trials:** The code now runs the simulation multiple times to demonstrate the random variation inherent in Monte Carlo methods. It also calculates the average and standard deviation of these estimates, giving you a better idea of the accuracy and variability.
* **`Random` package:** Explicitly imports the `Random` package, although `rand()` is often available without it in recent Julia versions. It's good practice to include it for clarity.
* **Comments:**  Added more comments to explain the code.

This improved example showcases the power and efficiency of Julia for numerical computations like Monte Carlo integration, and provides a more robust and informative demonstration of the technique.  You can easily adjust the function `f`, the integration limits `a` and `b`, and the number of samples `n` to explore different integration problems. Remember that increasing `n` will generally improve accuracy but also increase computation time.
